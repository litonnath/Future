{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceRecognization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQa7luTaQJbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBXXnm6N-ahm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "face_cascade=cv2.CascadeClassifier(\"/content/drive/My Drive/haarcascade_frontalface_alt.xml\")"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV6ndjesvQgc",
        "colab_type": "text"
      },
      "source": [
        "# Data of Images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0MDPdzqK-sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path=\"/content/drive/My Drive/5-celebrity-faces-dataset/data/train\"\n",
        "test_path=\"/content/drive/My Drive/5-celebrity-faces-dataset/data/val\""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8-i6q_vMiIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e3ea4713-0e29-41c9-a31c-bc8335585e81"
      },
      "source": [
        "pip install MTCNN"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: MTCNN in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from MTCNN) (2.3.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from MTCNN) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.0->MTCNN) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkMfiMWNMZFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "import cv2\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbckJAMavgzg",
        "colab_type": "text"
      },
      "source": [
        "# Extract Images from Folder with location of each images and split in training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo0g4sAHMc1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "def extract_face(image):\n",
        "    img = cv2.imread(image, cv2.IMREAD_UNCHANGED)\n",
        "    im=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        " \n",
        "    pixel=asarray(im)\n",
        "    detector=MTCNN()\n",
        "    results=detector.detect_faces(pixel)\n",
        "    \n",
        "    if len(results)>0:\n",
        "      \n",
        "      x1,y1,weight,height=results[0][\"box\"]\n",
        "      x1,y1=abs(x1),abs(y1)\n",
        "      x2,y2=x1+weight,y1+height\n",
        "      face=pixel[y1:y2,x1:x2]\n",
        "    \n",
        "    # image = Image.fromarray(face)\n",
        "    \n",
        "      image = cv2.resize(face,(160,160))\n",
        "      face_array = asarray(image)\n",
        "    \n",
        "      return face_array\n",
        "   \n",
        "      \n",
        " \n",
        " \n",
        " \n",
        "def load_faces(path):\n",
        "    faces=list()\n",
        "    for img in listdir(path):\n",
        "        image=path+img\n",
        "        \n",
        "        face=extract_face(image)\n",
        "        faces.append(face)\n",
        "    return faces\n",
        " \n",
        " \n",
        "def load_dataset(train_path):\n",
        "    x,y=list(),list()\n",
        "    for subfolder in listdir(train_path):\n",
        "        path=train_path+subfolder\n",
        " \n",
        "        if not isdir(path):\n",
        "            continue\n",
        "        \n",
        "        faces=load_faces(path+\"/\")\n",
        "        labels=[subfolder for i in range(len(faces))]\n",
        "        print('>loaded %d examples for class: %s' % (len(faces), subfolder))\n",
        "        x.extend(faces)\n",
        "        y.extend(labels)\n",
        "    return asarray(x),asarray(y)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRHfQx4uNUKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "01806583-391f-47fc-897f-d31ba23ba859"
      },
      "source": [
        "train_x,train_y=load_dataset(train_path+\"/\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">loaded 17 examples for class: madonna\n",
            ">loaded 16 examples for class: Liton\n",
            ">loaded 17 examples for class: mindy_kaling\n",
            ">loaded 21 examples for class: jerry_seinfeld\n",
            ">loaded 16 examples for class: elton_john\n",
            ">loaded 14 examples for class: ben_afflek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmxOuFsBNfWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d22243e3-38aa-4e85-c7a9-e1a15a64693d"
      },
      "source": [
        "test_x,test_y=load_dataset(test_path+\"/\")"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">loaded 5 examples for class: Liton\n",
            ">loaded 5 examples for class: mindy_kaling\n",
            ">loaded 5 examples for class: madonna\n",
            ">loaded 5 examples for class: jerry_seinfeld\n",
            ">loaded 5 examples for class: elton_john\n",
            ">loaded 5 examples for class: ben_afflek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ril69s8TPkKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4c334b7-e3d2-4b6e-956f-b1e6eb281b48"
      },
      "source": [
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101, 160, 160, 3)\n",
            "(101,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alB0tR0ZPzB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b25c898-dc11-4d4c-d9f7-c6a1a8435d39"
      },
      "source": [
        "print(test_x.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 160, 160, 3)\n",
            "(30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naB3NEmjwB8K",
        "colab_type": "text"
      },
      "source": [
        "# Saved into zip format images and load this data for train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFpBLayFP-Fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "savez_compressed(\"faceRecognitionload_faces.npz\",train_x,train_y,test_x,test_y)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHgBO5RQRYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load,savez_compressed,asarray,expand_dims"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbJYaYm1QtUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "data=load(\"faceRecognitionload_faces.npz\")"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw1j6vFHQ0Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#arr_0 to arr_3 it is a format of zip comprezzed file\n",
        "train_x,train_y,test_x,test_y=data[\"arr_0\"],data[\"arr_1\"],data[\"arr_2\"],data[\"arr_3\"]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_OPc6VZ_e3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let this is our test data \n",
        "#5 is a selection\n",
        "# s=test_x[5]\n",
        "# import matplotlib.pyplot as plt\n",
        " \n",
        "# plt.imshow(s)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN9SRm8DwYBA",
        "colab_type": "text"
      },
      "source": [
        "# Predefined Model and load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAltRgbxQeVd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f846a76e-8dc2-46a4-dbf3-aec7a335f46c"
      },
      "source": [
        "model=load_model(\"/content/drive/My Drive/facenet_keras.h5\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XOhNQVQXMUE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "84461917-3cbb-4b4f-8231-850d8ea16d17"
      },
      "source": [
        "print(\"train_x shape\",train_x.shape)\n",
        " \n",
        "print(\"train_y shape\",train_y.shape)\n",
        "print(\"test x shape\",test_x.shape)\n",
        "print(\"test y shape\",test_y.shape)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x shape (101, 160, 160, 3)\n",
            "train_y shape (101,)\n",
            "test x shape (30, 160, 160, 3)\n",
            "test y shape (30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQK5xOim13KB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "497690ff-bee0-41bd-b7b5-b3024a75f243"
      },
      "source": [
        "test_x[0].shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 160, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoegwuTUwsUs",
        "colab_type": "text"
      },
      "source": [
        "# Pixel of image array ,it convert it into embedding vector or standarization of data of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o0hiQhnQm-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def get_embedding(model,pixel):\n",
        "    face_pixel=pixel.astype(\"float32\")\n",
        "    mean,std=face_pixel.mean(),face_pixel.std()\n",
        "    # print(\"Face Pixel\",face_pixel)\n",
        "    #below we are standarising our fixel \n",
        "    face_pixel=(face_pixel-mean)/std\n",
        "    # print(\"Facce PiXEL 2\",face_pixel.shape)\n",
        "    sample=expand_dims(face_pixel,axis=0)\n",
        " \n",
        "    # print(\"Sample\",sample.shape)\n",
        "    prediction=model.predict(sample)\n",
        "    # print(prediction.shape)\n",
        "    #(1,128)\n",
        "    return prediction[0]\n",
        " \n",
        " \n",
        "#transform your image into vector first train \n",
        "newtrainx=list()\n",
        "for face_pixel in train_x:\n",
        "    \n",
        "    #we have resize it because facenet keras has shape 160,160 that's i resize it\n",
        "#     face_pixel=np.resize(face_pixel,(160,160,3))\n",
        "#     face_pixel=asarray(face_pixel)\n",
        "    \n",
        "    embedding=get_embedding(model,face_pixel)\n",
        "    newtrainx.append(embedding)\n",
        "newtrainx=asarray(newtrainx)\n",
        "#then testing data\n",
        "newtestx=list()\n",
        "for face_pixel2 in test_x:\n",
        "#     face_pixel2=np.resize(face_pixel2,(160,160,3))\n",
        "#     face_pixel2=asarray(face_pixel2)\n",
        "    embedding2=get_embedding(model,face_pixel2)\n",
        "    newtestx.append(embedding2)\n",
        "newtestx=asarray(newtestx)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KUitNM5RD_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "savez_compressed(\"faceRecognitionload_faces2.npz\",newtrainx,train_y,newtestx,test_y)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3gY0PxhEhJf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "790f7918-2c62-47c7-f23f-edcaed7cd294"
      },
      "source": [
        "newtestx.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qUkjRg4gNyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5efbb248-3e5a-4939-8747-3150cebcdd50"
      },
      "source": [
        "newtestx[0].shape"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmAFLaO6xSWB",
        "colab_type": "text"
      },
      "source": [
        "# Capture Image through webcam ,we can't open open through opencv ,this  api created by google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0fvCSIIvJn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        " \n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        " \n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        " \n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        " \n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        " \n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        " \n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcETygH0Yhk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filename=take_photo()"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afoadHl_QfuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filename\n",
        "# photo.jpg"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnfjg3FyxxTK",
        "colab_type": "text"
      },
      "source": [
        "# prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2-zr8MSRPT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b543c4a3-909b-41b7-ea2a-8aa9698c0657"
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "# load faces\n",
        "# data = load('faceRecognitionload_faces.npz')\n",
        "#below is a testing data -test_x\n",
        "# testX_faces = data['arr_2']\n",
        "# load face embeddings\n",
        "data = load('faceRecognitionload_faces2.npz')\n",
        "trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
        "# normalize input vectors\n",
        "in_encoder = Normalizer(norm='l2')\n",
        "trainX = in_encoder.transform(trainX)\n",
        "testX = in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder = LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy = out_encoder.transform(trainy)\n",
        "testy = out_encoder.transform(testy)\n",
        "# fit model\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(trainX, trainy)\n",
        "# test model on a random example from the test dataset\n",
        " \n",
        "# selection = choice([i for i in range(testX.shape[0])])\n",
        "# print(\"selection\",selection)\n",
        "#5 ,it is for random image selection\n",
        "#below is a test image for plotting\n",
        "# choose=\"Image\"\n",
        " \n",
        "#Just for displaying test data\n",
        "# image=\"/content/drive/My Drive/IMG_20190328_142112_474.jpg\"\n",
        " \n",
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  #below is a file name which is stored in jpg extension \n",
        "  # print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        " \n",
        "  # imgr=cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
        "  # cv2_imshow(imgr)\n",
        "  \n",
        "  # display(Image(filename))\n",
        "  \n",
        "except Exception as err:\n",
        "  \n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))\n",
        "#image name is given\n",
        "image=\"photo.jpg\"\n",
        "a=extract_face(image)\n",
        "random_face_pixels=a.any()\n",
        "# print(random_face_pixels)\n",
        "model1=load_model(\"/content/drive/My Drive/facenet_keras.h5\")\n",
        "\n",
        "#if image is not detected it means is None.If detected it has some value\n",
        "if random_face_pixels!=None:\n",
        "  s=get_embedding(model1,a)\n",
        "  random_face_emb = s\n",
        "  #this is aclass if selecction is 5 it will be 5th\n",
        "  # import random\n",
        "  # j=random.randint(0,30)\n",
        "  random_face_class = testy[0]\n",
        " \n",
        "  random_face_name = out_encoder.inverse_transform([random_face_class])\n",
        "  # print(random_face_name,\"name of the person\")\n",
        "  # prediction for the face\n",
        "  samples = expand_dims(random_face_emb, axis=0)\n",
        "  #samples (1, 128)\n",
        "  # print(\"samples\",samples.shape)\n",
        "  yhat_class = model.predict(samples)\n",
        "  print(\"class\",yhat_class)\n",
        "  #class (1,) class [0]\n",
        "  yhat_prob = model.predict_proba(samples)\n",
        "  #[[9.99999744e-01 3.81907437e-08 9.86691609e-08 2.36270613e-08\n",
        "  # 3.27224649e-08 6.26039307e-08]]\n",
        "  # print(yhat_prob)\n",
        "  #prob (1, 6)\n",
        "  # get name\n",
        "  class_index = yhat_class[0]\n",
        "  #0 is a index\n",
        "  # print(class_index)\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  predict_names = out_encoder.inverse_transform(yhat_class)\n",
        "  #print(predict_names) ['Liton']\n",
        "  #It will tell you the name of the predict class.\n",
        "  print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
        "  # print('Expected: %s' % random_face_name[0])\n",
        "  if predict_names[0]==random_face_name[0]:\n",
        "    print(\"Access Granted : Face Recognized\")\n",
        " \n",
        "  else:\n",
        "    print(\"Access Denied : Not Recognized \")\n",
        "else:\n",
        "  print(\"Face is Not detected \")\n",
        "# plot for fun\n",
        "# pyplot.imshow(random_face_pixels)\n",
        "# title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
        "# pyplot.title(title)\n",
        "# pyplot.show()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              " \n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              " \n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              " \n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              " \n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              " \n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "class [4]\n",
            "Predicted: madonna (100.000)\n",
            "Access Denied : Not Recognized \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVR0-K7WRUvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-0plLw737d4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuJXF8HRLdZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlQ7vEj-fSMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR6JB2Rssig7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_jZxJfXkgSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}