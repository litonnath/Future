{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "# it is used to covert my text to speech pyttsx3\n",
    "import pyttsx3\n",
    "#recognise speech  word\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below we create a object for voice taken from pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "#get voice from module\n",
    "voices = engine.getProperty('voices')\n",
    "#there are so many voice we choose a location of voice which want to use through its index with its id\n",
    "# print(voices[1].id)\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "#set the frequency of  the sound how much you want\n",
    "engine.setProperty('rate', 150)\n",
    "\n",
    "def speak(audio):\n",
    "    #say listen until you can't reply\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def takeCommand():\n",
    "    #It takes microphone input from the user and returns string output\n",
    "    #here below a we create object to recognize audio of human \n",
    "    r = sr.Recognizer()\n",
    "    #get audio  from the microphone \n",
    "    with sr.Microphone() as source:\n",
    "        #adjust ambient noise is for removing background  voice \n",
    "        audio = r.adjust_for_ambient_noise(source)\n",
    "        print(\"Listening...\")\n",
    "        #hear until 1min if u can't respond\n",
    "        r.pause_threshold = 1\n",
    "        #it will listen u\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        print(\"Recognizing...\")   \n",
    "        #recognise  your language through google english-indian\n",
    "        query = r.recognize_google(audio, language='en-in')\n",
    "        print(f\"User said: {query}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(e)    \n",
    "        print(\"Say that again please...\")  \n",
    "        return \"None\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath = \"chats//\"\n",
    "# human = []\n",
    "# bot = []\n",
    "\n",
    "# for files in os.listdir(basepath):\n",
    "#     data = open(os.path.join(basepath,files),'r').readlines()\n",
    "#     for i in data:\n",
    "#         if '- - ' in i:\n",
    "#             human.append(i)\n",
    "# #             print('human: ',i)\n",
    "#         else:\n",
    "# #             print('bot',i)\n",
    "#             bot.append(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def clean_data(text):\n",
    "    #it is used to replace this term re.sub(pattern,replace,string)\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    #it is used to find all the matches and remove emoji\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)',text)\n",
    "    #replace punctuation \n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    rm_words = [w for w in text.split() if w.lower() not in stop_words]\n",
    "    return ' '.join(rm_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "basepath = \"chats//\"\n",
    "chat = []\n",
    "for files in os.listdir(basepath):\n",
    "    data = open(os.path.join(basepath,files),'r').readlines()\n",
    "    for i in data:\n",
    "        if '- - ' in i:\n",
    "#             human.append(i)\n",
    "            chat.append(['human',i])\n",
    "        else:\n",
    "#             print('bot',i)\n",
    "            chat.append(['bot',i])\n",
    "#             bot.append(i)\n",
    "chats = pd.DataFrame(chat, columns=['source','text'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats = pd.read_csv('rdany_conversations_2016-03-01.csv')\n",
    "chats = chats[['source','text']]\n",
    "chats['train_text'] = chats['text'].apply(clean_data)\n",
    "\n",
    "human = []\n",
    "bot = []\n",
    "for i in range(len(chats)):\n",
    "    #here we are checking human and bot if it not similiar we will continue\n",
    "    if chats.iloc[i,0]==chats.iloc[i-1,0]:\n",
    "        continue\n",
    "    if chats.iloc[i,0] == 'human':\n",
    "        human.append(chats.iloc[i,-1])\n",
    "    else:\n",
    "        bot.append(chats.iloc[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "\n",
    "def LemTokens(tokens):\n",
    "    #split the text and store in list\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "#we are creating a dictionary of punctuation\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    #call above function and parameter in word tokenize  and lower text value\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "\n",
    "    user_response = [user_response]\n",
    "    robo_response=''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(human)\n",
    "    tfidf_user_response = TfidfVec.transform(user_response)\n",
    "    vals = cosine_similarity(tfidf_user_response, tfidf)\n",
    "    #this will give you the index value\n",
    "    idx=vals.argsort()[0][-1]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-1]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return (robo_response)\n",
    "    else:\n",
    "        robo_response = robo_response+bot[idx]\n",
    "        return (robo_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "print(\"ROBO: My name is Robo. I will answer your queries. If you want to exit, type Bye!\")\n",
    "speak(\"My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = takeCommand()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            print(\"ROBO: \",end=\"\")\n",
    "            print(response(user_response))\n",
    "            speak(response(user_response))\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")\n",
    "        speak(\"Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
